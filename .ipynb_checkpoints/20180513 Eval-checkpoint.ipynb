{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import visdom\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import timeit\n",
    "    \n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ptsemseg.models import get_model\n",
    "from ptsemseg.loader import get_loader, get_data_path\n",
    "from ptsemseg.metrics import runningScore\n",
    "from ptsemseg.loss import *\n",
    "from ptsemseg.augmentations import *\n",
    "from ptsemseg.utils import convert_state_dict\n",
    "\n",
    "from SUNRGBDLoader import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Hyperparams')\n",
    "parser.add_argument('--model_path', nargs='?', type=str, default='fcn8s_pascal_1_26.pkl', \n",
    "                    help='Path to the saved model')\n",
    "parser.add_argument('--model_name', nargs='?', type=str, default='fcn8s', \n",
    "                    help='model name')\n",
    "parser.add_argument('--dataset', nargs='?', type=str, default='pascal', \n",
    "                    help='Dataset to use [\\'pascal, camvid, ade20k etc\\']')\n",
    "parser.add_argument('--img_rows', nargs='?', type=int, default=256, \n",
    "                    help='Height of the input image')\n",
    "parser.add_argument('--img_cols', nargs='?', type=int, default=256, \n",
    "                    help='Width of the input image')\n",
    "\n",
    "parser.add_argument('--img_norm', dest='img_norm', action='store_true', \n",
    "                    help='Enable input image scales normalization [0, 1] | True by default')\n",
    "parser.add_argument('--no-img_norm', dest='img_norm', action='store_false', \n",
    "                    help='Disable input image scales normalization [0, 1] | True by default')\n",
    "parser.set_defaults(img_norm=True)\n",
    "\n",
    "parser.add_argument('--eval_flip', dest='eval_flip', action='store_true', \n",
    "                    help='Enable evaluation with flipped image | True by default')\n",
    "parser.add_argument('--no-eval_flip', dest='eval_flip', action='store_false', \n",
    "                    help='Disable evaluation with flipped image | True by default')\n",
    "parser.set_defaults(eval_flip=True)\n",
    "\n",
    "parser.add_argument('--batch_size', nargs='?', type=int, default=1, \n",
    "                    help='Batch Size')\n",
    "parser.add_argument('--split', nargs='?', type=str, default='val', \n",
    "                    help='Split of dataset to test on')\n",
    "\n",
    "parser.add_argument('--measure_time', dest='measure_time', action='store_true', \n",
    "                    help='Enable evaluation with time (fps) measurement | True by default')\n",
    "parser.add_argument('--no-measure_time', dest='measure_time', action='store_false', \n",
    "                    help='Disable evaluation with time (fps) measurement | True by default')\n",
    "parser.set_defaults(measure_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1462: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................Overall Acc: \t 0.447841536458\n",
      "Mean Acc : \t 0.101947222172\n",
      "FreqW Acc : \t 0.272714266563\n",
      "Mean IoU : \t 0.0675627905541\n",
      "0 0.249074136085\n",
      "1 0.430276795776\n",
      "2 0.546283881541\n",
      "3 0.171654983593\n",
      "4 0.157893929918\n",
      "5 0.280177820534\n",
      "6 1.03728521713e-05\n",
      "7 0.0262749524845\n",
      "8 0.00652911389507\n",
      "9 0.0385873947465\n",
      "10 0.0\n",
      "11 0.0057402282275\n",
      "12 0.0\n",
      "13 0.0495256392482\n",
      "14 0.000172272271258\n",
      "15 0.0\n",
      "16 0.0790386869871\n",
      "17 5.35596263252e-06\n",
      "18 0.00688231930182\n",
      "19 0.0\n",
      "20 0.0\n",
      "21 0.0\n",
      "22 0.0782495268811\n",
      "23 0.169430945289\n",
      "24 0.0\n",
      "25 0.0\n",
      "26 0.0\n",
      "27 0.0\n",
      "28 nan\n",
      "29 0.00132652324574\n",
      "30 0.0\n",
      "31 0.0\n",
      "32 0.0\n",
      "33 nan\n",
      "34 nan\n",
      "35 0.0\n",
      "36 nan\n",
      "37 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args('--batch_size 3'.split(' '))\n",
    "\n",
    "model_file_name = 'fcn8s_SUNRGBD_best_model.pkl'\n",
    "model_name = 'fcn8s'\n",
    "\n",
    "\n",
    "data_path = '/home/dongwonshin/Desktop/Datasets/SUNRGBD/SUNRGBD(light)/'\n",
    "t_loader = SUNRGBDLoader(data_path, is_transform=True)\n",
    "v_loader = SUNRGBDLoader(data_path, is_transform=True, split='val')\n",
    "\n",
    "n_classes = t_loader.n_classes\n",
    "trainloader = data.DataLoader(t_loader, batch_size=args.batch_size, num_workers=16, shuffle=True)\n",
    "valloader = data.DataLoader(v_loader, batch_size=args.batch_size, num_workers=16)\n",
    "\n",
    "# Setup Metrics\n",
    "running_metrics = runningScore(n_classes)\n",
    "\n",
    "# Setup Model\n",
    "print(model_name)\n",
    "model = get_model(model_name, n_classes, version='SUNRGBD')\n",
    "state = convert_state_dict(torch.load(model_file_name)['model_state'])\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "for i, (images, depths, labels) in enumerate(valloader):\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    images = Variable(images.cuda(), volatile=True)\n",
    "    #labels = Variable(labels.cuda(), volatile=True)\n",
    "\n",
    "    if args.eval_flip:\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Flip images in numpy (not support in tensor)\n",
    "        outputs = outputs.data.cpu().numpy()\n",
    "        flipped_images = np.copy(images.data.cpu().numpy()[:, :, :, ::-1])\n",
    "        flipped_images = Variable(torch.from_numpy( flipped_images ).float().cuda(), volatile=True)\n",
    "        outputs_flipped = model( flipped_images )\n",
    "        outputs_flipped = outputs_flipped.data.cpu().numpy()\n",
    "        outputs = (outputs + outputs_flipped[:, :, :, ::-1]) / 2.0\n",
    "\n",
    "        pred = np.argmax(outputs, axis=1)\n",
    "    else:\n",
    "        outputs = model(images)\n",
    "        pred = outputs.data.max(1)[1].cpu().numpy()\n",
    "\n",
    "    #gt = labels.data.cpu().numpy()\n",
    "    gt = labels.numpy()\n",
    "\n",
    "    if args.measure_time:\n",
    "        elapsed_time = timeit.default_timer() - start_time\n",
    "        # print('Inference time (iter {0:5d}): {1:3.5f} fps'.format(i+1, pred.shape[0]/elapsed_time))\n",
    "        sys.stdout.write('.')\n",
    "    running_metrics.update(gt, pred)\n",
    "\n",
    "score, class_iou = running_metrics.get_scores()\n",
    "\n",
    "for k, v in score.items():\n",
    "    print(k, v)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    print(i, class_iou[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(args):\n",
    "\n",
    "    model_file_name = args.model_path\n",
    "    model_name = args.model_name\n",
    "    \n",
    "    data_path = '/home/dongwonshin/Desktop/Datasets/SUNRGBD/SUNRGBD(light)/'\n",
    "    t_loader = SUNRGBDLoader(data_path, is_transform=True)\n",
    "    v_loader = SUNRGBDLoader(data_path, is_transform=True, split='val')\n",
    "\n",
    "    n_classes = t_loader.n_classes\n",
    "    trainloader = data.DataLoader(t_loader, batch_size=args.batch_size, num_workers=16, shuffle=True)\n",
    "    valloader = data.DataLoader(v_loader, batch_size=args.batch_size, num_workers=16)\n",
    "\n",
    "    # Setup Metrics\n",
    "    running_metrics = runningScore(n_classes)\n",
    "\n",
    "    # Setup Model\n",
    "    print(model_name)\n",
    "    model = get_model(model_name, n_classes, version='SUNRGBD')\n",
    "    state = convert_state_dict(torch.load(model_file_name)['model_state'])\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    for i, (images, depths, labels) in enumerate(valloader):\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        images = Variable(images.cuda(), volatile=True)\n",
    "        depths = Variable(depths.cuda(), volatile=True)\n",
    "        #labels = Variable(labels.cuda(), volatile=True)\n",
    "\n",
    "        outputs = model(images, depths)\n",
    "        pred = outputs.data.max(1)[1].cpu().numpy()\n",
    "\n",
    "        #gt = labels.data.cpu().numpy()\n",
    "        gt = labels.numpy()\n",
    "\n",
    "        if args.measure_time:\n",
    "            elapsed_time = timeit.default_timer() - start_time\n",
    "            # print('Inference time (iter {0:5d}): {1:3.5f} fps'.format(i+1, pred.shape[0]/elapsed_time))\n",
    "            sys.stdout.write('.')\n",
    "        running_metrics.update(gt, pred)\n",
    "\n",
    "    score, class_iou = running_metrics.get_scores()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        print(k, v)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        print(i, class_iou[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn8s_with_rgbd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1462: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................Overall Acc: \t 0.44011656901\n",
      "Mean Acc : \t 0.11045726581\n",
      "FreqW Acc : \t 0.265374134817\n",
      "Mean IoU : \t 0.066229933286\n",
      "0 0.222684463495\n",
      "1 0.432825665971\n",
      "2 0.535543054936\n",
      "3 0.156842976007\n",
      "4 0.150205184366\n",
      "5 0.287286284537\n",
      "6 0.0\n",
      "7 0.0296811700781\n",
      "8 0.015454627481\n",
      "9 0.0824143703835\n",
      "10 0.00106554465725\n",
      "11 0.0142328951761\n",
      "12 0.0\n",
      "13 0.0669075744233\n",
      "14 0.001567859614\n",
      "15 0.0\n",
      "16 0.0960082982047\n",
      "17 0.000532845105125\n",
      "18 0.0295838940002\n",
      "19 5.82381503563e-05\n",
      "20 0.0\n",
      "21 0.0\n",
      "22 0.0934718076271\n",
      "23 0.1643533413\n",
      "24 0.0\n",
      "25 0.0\n",
      "26 0.0\n",
      "27 0.0\n",
      "28 0.0\n",
      "29 0.00337402664318\n",
      "30 0.0\n",
      "31 0.0\n",
      "32 0.0\n",
      "33 nan\n",
      "34 nan\n",
      "35 0.000183476138928\n",
      "36 0.0\n",
      "37 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "validate(parser.parse_args('--model_path fcn8s_with_rgbd_SUNRGBD_best_model.pkl --model_name fcn8s_with_rgbd --batch_size 3'.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn8s_rgbd_renet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1462: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................Overall Acc: \t 0.443091634115\n",
      "Mean Acc : \t 0.0969299141882\n",
      "FreqW Acc : \t 0.2710813512\n",
      "Mean IoU : \t 0.0622627777268\n",
      "0 0.238882397385\n",
      "1 0.443428914937\n",
      "2 0.548705216511\n",
      "3 0.0736231185203\n",
      "4 0.142021636248\n",
      "5 0.288615972038\n",
      "6 0.0\n",
      "7 0.0508401838307\n",
      "8 0.0028211689063\n",
      "9 0.0339427438647\n",
      "10 0.0\n",
      "11 0.047148767828\n",
      "12 0.0\n",
      "13 0.0\n",
      "14 0.00509782978104\n",
      "15 0.0\n",
      "16 0.0\n",
      "17 0.00104271779347\n",
      "18 0.0130868510106\n",
      "19 0.000323993345395\n",
      "20 0.0\n",
      "21 0.0\n",
      "22 0.0436598283101\n",
      "23 0.180701270017\n",
      "24 0.0\n",
      "25 0.0\n",
      "26 0.0\n",
      "27 0.0\n",
      "28 nan\n",
      "29 0.00299183238636\n",
      "30 0.0\n",
      "31 0.0\n",
      "32 0.0\n",
      "33 nan\n",
      "34 nan\n",
      "35 0.0\n",
      "36 nan\n",
      "37 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "validate(parser.parse_args('--model_path fcn8s_rgbd_renet_SUNRGBD_best_model.pkl --model_name fcn8s_rgbd_renet --batch_size 3'.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
