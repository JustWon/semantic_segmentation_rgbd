{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import visdom\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import timeit\n",
    "    \n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ptsemseg.models import get_model\n",
    "from ptsemseg.loader import get_loader, get_data_path\n",
    "from ptsemseg.metrics import runningScore\n",
    "from ptsemseg.loss import *\n",
    "from ptsemseg.augmentations import *\n",
    "from ptsemseg.utils import convert_state_dict\n",
    "\n",
    "from SUNRGBDLoader import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Hyperparams')\n",
    "parser.add_argument('--model_path', nargs='?', type=str, default='fcn8s_pascal_1_26.pkl', \n",
    "                    help='Path to the saved model')\n",
    "parser.add_argument('--model_name', nargs='?', type=str, default='fcn8s', \n",
    "                    help='model name')\n",
    "parser.add_argument('--dataset', nargs='?', type=str, default='pascal', \n",
    "                    help='Dataset to use [\\'pascal, camvid, ade20k etc\\']')\n",
    "parser.add_argument('--img_rows', nargs='?', type=int, default=256, \n",
    "                    help='Height of the input image')\n",
    "parser.add_argument('--img_cols', nargs='?', type=int, default=256, \n",
    "                    help='Width of the input image')\n",
    "\n",
    "parser.add_argument('--img_norm', dest='img_norm', action='store_true', \n",
    "                    help='Enable input image scales normalization [0, 1] | True by default')\n",
    "parser.add_argument('--no-img_norm', dest='img_norm', action='store_false', \n",
    "                    help='Disable input image scales normalization [0, 1] | True by default')\n",
    "parser.set_defaults(img_norm=True)\n",
    "\n",
    "parser.add_argument('--eval_flip', dest='eval_flip', action='store_true', \n",
    "                    help='Enable evaluation with flipped image | True by default')\n",
    "parser.add_argument('--no-eval_flip', dest='eval_flip', action='store_false', \n",
    "                    help='Disable evaluation with flipped image | True by default')\n",
    "parser.set_defaults(eval_flip=True)\n",
    "\n",
    "parser.add_argument('--batch_size', nargs='?', type=int, default=1, \n",
    "                    help='Batch Size')\n",
    "parser.add_argument('--split', nargs='?', type=str, default='val', \n",
    "                    help='Split of dataset to test on')\n",
    "\n",
    "parser.add_argument('--measure_time', dest='measure_time', action='store_true', \n",
    "                    help='Enable evaluation with time (fps) measurement | True by default')\n",
    "parser.add_argument('--no-measure_time', dest='measure_time', action='store_false', \n",
    "                    help='Disable evaluation with time (fps) measurement | True by default')\n",
    "parser.set_defaults(measure_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1462: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................Overall Acc: \t 0.589247851563\n",
      "Mean Acc : \t 0.487283177548\n",
      "FreqW Acc : \t 0.423659570128\n",
      "Mean IoU : \t 0.340161510096\n",
      "0 0.241689351302\n",
      "1 0.371807567746\n",
      "2 0.0355507575476\n",
      "3 0.32244010827\n",
      "4 0.520843064977\n",
      "5 0.684652680747\n",
      "6 0.339476466794\n",
      "7 0.154814833446\n",
      "8 0.356848960797\n",
      "9 0.406725535261\n",
      "10 0.288021937999\n",
      "11 0.0011320754717\n",
      "12 0.585418230521\n",
      "13 0.452839570463\n",
      "14 nan\n",
      "15 nan\n",
      "16 nan\n",
      "17 nan\n",
      "18 nan\n",
      "19 nan\n",
      "20 nan\n",
      "21 nan\n",
      "22 nan\n",
      "23 nan\n",
      "24 nan\n",
      "25 nan\n",
      "26 nan\n",
      "27 nan\n",
      "28 nan\n",
      "29 nan\n",
      "30 nan\n",
      "31 nan\n",
      "32 nan\n",
      "33 nan\n",
      "34 nan\n",
      "35 nan\n",
      "36 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args('--batch_size 3'.split(' '))\n",
    "\n",
    "model_file_name = 'fcn8s_SUNRGBD_best_model.pkl'\n",
    "model_name = 'fcn8s'\n",
    "\n",
    "\n",
    "data_path = '/home/dongwonshin/Desktop/Datasets/SUNRGBD/SUNRGBD(light)/'\n",
    "t_loader = SUNRGBDLoader(data_path, is_transform=True)\n",
    "v_loader = SUNRGBDLoader(data_path, is_transform=True, split='val')\n",
    "\n",
    "n_classes = t_loader.n_classes\n",
    "trainloader = data.DataLoader(t_loader, batch_size=args.batch_size, num_workers=16, shuffle=True)\n",
    "valloader = data.DataLoader(v_loader, batch_size=args.batch_size, num_workers=16)\n",
    "\n",
    "# Setup Metrics\n",
    "running_metrics = runningScore(n_classes)\n",
    "\n",
    "# Setup Model\n",
    "print(model_name)\n",
    "model = get_model(model_name, n_classes, version='SUNRGBD')\n",
    "state = convert_state_dict(torch.load(model_file_name)['model_state'])\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "for i, (images, depths, labels) in enumerate(valloader):\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    images = Variable(images.cuda(), volatile=True)\n",
    "    #labels = Variable(labels.cuda(), volatile=True)\n",
    "\n",
    "    if args.eval_flip:\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Flip images in numpy (not support in tensor)\n",
    "        outputs = outputs.data.cpu().numpy()\n",
    "        flipped_images = np.copy(images.data.cpu().numpy()[:, :, :, ::-1])\n",
    "        flipped_images = Variable(torch.from_numpy( flipped_images ).float().cuda(), volatile=True)\n",
    "        outputs_flipped = model( flipped_images )\n",
    "        outputs_flipped = outputs_flipped.data.cpu().numpy()\n",
    "        outputs = (outputs + outputs_flipped[:, :, :, ::-1]) / 2.0\n",
    "\n",
    "        pred = np.argmax(outputs, axis=1)\n",
    "    else:\n",
    "        outputs = model(images)\n",
    "        pred = outputs.data.max(1)[1].cpu().numpy()\n",
    "\n",
    "    #gt = labels.data.cpu().numpy()\n",
    "    gt = labels.numpy()\n",
    "\n",
    "    if args.measure_time:\n",
    "        elapsed_time = timeit.default_timer() - start_time\n",
    "        # print('Inference time (iter {0:5d}): {1:3.5f} fps'.format(i+1, pred.shape[0]/elapsed_time))\n",
    "        sys.stdout.write('.')\n",
    "    running_metrics.update(gt, pred)\n",
    "\n",
    "score, class_iou = running_metrics.get_scores()\n",
    "\n",
    "for k, v in score.items():\n",
    "    print(k, v)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    print(i, class_iou[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(args):\n",
    "\n",
    "    model_file_name = args.model_path\n",
    "    model_name = args.model_name\n",
    "    \n",
    "    data_path = '/home/dongwonshin/Desktop/Datasets/SUNRGBD/SUNRGBD(light)/'\n",
    "    t_loader = SUNRGBDLoader(data_path, is_transform=True)\n",
    "    v_loader = SUNRGBDLoader(data_path, is_transform=True, split='val')\n",
    "\n",
    "    n_classes = t_loader.n_classes\n",
    "    trainloader = data.DataLoader(t_loader, batch_size=args.batch_size, num_workers=16, shuffle=True)\n",
    "    valloader = data.DataLoader(v_loader, batch_size=args.batch_size, num_workers=16)\n",
    "\n",
    "    # Setup Metrics\n",
    "    running_metrics = runningScore(n_classes)\n",
    "\n",
    "    # Setup Model\n",
    "    print(model_name)\n",
    "    model = get_model(model_name, n_classes, version='SUNRGBD')\n",
    "    state = convert_state_dict(torch.load(model_file_name)['model_state'])\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    for i, (images, depths, labels) in enumerate(valloader):\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        images = Variable(images.cuda(), volatile=True)\n",
    "        depths = Variable(depths.cuda(), volatile=True)\n",
    "        #labels = Variable(labels.cuda(), volatile=True)\n",
    "\n",
    "        outputs = model(images, depths)\n",
    "        pred = outputs.data.max(1)[1].cpu().numpy()\n",
    "\n",
    "        #gt = labels.data.cpu().numpy()\n",
    "        gt = labels.numpy()\n",
    "\n",
    "        if args.measure_time:\n",
    "            elapsed_time = timeit.default_timer() - start_time\n",
    "            # print('Inference time (iter {0:5d}): {1:3.5f} fps'.format(i+1, pred.shape[0]/elapsed_time))\n",
    "            sys.stdout.write('.')\n",
    "        running_metrics.update(gt, pred)\n",
    "\n",
    "    score, class_iou = running_metrics.get_scores()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        print(k, v)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        print(i, class_iou[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn8s_with_rgbd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1462: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................Overall Acc: \t 0.58202203776\n",
      "Mean Acc : \t 0.485067179282\n",
      "FreqW Acc : \t 0.418053342883\n",
      "Mean IoU : \t 0.338458978355\n",
      "0 0.240576629271\n",
      "1 0.403996244209\n",
      "2 0.0410123847371\n",
      "3 0.314498757781\n",
      "4 0.502610874241\n",
      "5 0.652879022039\n",
      "6 0.34017055544\n",
      "7 0.144884394649\n",
      "8 0.356367245462\n",
      "9 0.401690646753\n",
      "10 0.257652920962\n",
      "11 0.104078064748\n",
      "12 0.58618915044\n",
      "13 0.391818806231\n",
      "14 nan\n",
      "15 nan\n",
      "16 nan\n",
      "17 nan\n",
      "18 nan\n",
      "19 nan\n",
      "20 nan\n",
      "21 nan\n",
      "22 nan\n",
      "23 nan\n",
      "24 nan\n",
      "25 nan\n",
      "26 nan\n",
      "27 nan\n",
      "28 nan\n",
      "29 nan\n",
      "30 nan\n",
      "31 nan\n",
      "32 nan\n",
      "33 nan\n",
      "34 nan\n",
      "35 nan\n",
      "36 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "validate(parser.parse_args('--model_path fcn8s_with_rgbd_SUNRGBD_best_model.pkl --model_name fcn8s_with_rgbd --batch_size 3'.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
