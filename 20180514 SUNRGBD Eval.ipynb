{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import collections\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy.misc as m\n",
    "import scipy.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from SUNRGBDLoader import *\n",
    "from NYUDv2Loader import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import visdom\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import timeit\n",
    "    \n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ptsemseg.models import get_model\n",
    "from ptsemseg.loader import get_loader, get_data_path\n",
    "from ptsemseg.metrics import runningScore\n",
    "from ptsemseg.loss import *\n",
    "from ptsemseg.augmentations import *\n",
    "from ptsemseg.utils import convert_state_dict\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Hyperparams')\n",
    "parser.add_argument('--model_path', nargs='?', type=str, default='fcn8s_pascal_1_26.pkl', help='Path to the saved model')\n",
    "parser.add_argument('--model_name', nargs='?', type=str, default='fcn8s', help='model name')\n",
    "parser.add_argument('--dataset', nargs='?', type=str, default='pascal', help='Dataset to use [\\'pascal, camvid, ade20k etc\\']')\n",
    "parser.add_argument('--img_rows', nargs='?', type=int, default=256, help='Height of the input image')\n",
    "parser.add_argument('--img_cols', nargs='?', type=int, default=256, help='Width of the input image')\n",
    "\n",
    "parser.add_argument('--img_norm', dest='img_norm', action='store_true', help='Enable input image scales normalization [0, 1] | True by default')\n",
    "parser.add_argument('--no-img_norm', dest='img_norm', action='store_false', help='Disable input image scales normalization [0, 1] | True by default')\n",
    "parser.set_defaults(img_norm=True)\n",
    "\n",
    "parser.add_argument('--eval_flip', dest='eval_flip', action='store_true', help='Enable evaluation with flipped image | True by default')\n",
    "parser.add_argument('--no-eval_flip', dest='eval_flip', action='store_false', help='Disable evaluation with flipped image | True by default')\n",
    "parser.set_defaults(eval_flip=True)\n",
    "\n",
    "parser.add_argument('--batch_size', nargs='?', type=int, default=1, help='Batch Size')\n",
    "parser.add_argument('--split', nargs='?', type=str, default='val', help='Split of dataset to test on')\n",
    "\n",
    "parser.add_argument('--measure_time', dest='measure_time', action='store_true', help='Enable evaluation with time (fps) measurement | True by default')\n",
    "parser.add_argument('--no-measure_time', dest='measure_time', action='store_false', help='Disable evaluation with time (fps) measurement | True by default')\n",
    "parser.set_defaults(measure_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(args):\n",
    "\n",
    "    model_name = args.model_name\n",
    "\n",
    "    if (args.dataset == 'NYUDv2'):\n",
    "        data_path = '/home/dongwonshin/Desktop/Datasets/NYUDv2/'\n",
    "        t_loader = NYUDv2Loader(data_path, is_transform=True)\n",
    "        v_loader = NYUDv2Loader(data_path, is_transform=True, split='val')\n",
    "    elif (args.dataset == 'SUNRGBD'):\n",
    "        data_path = '/home/dongwonshin/Desktop/Datasets/SUNRGBD/SUNRGBD(light)/'\n",
    "        t_loader = SUNRGBDLoader(data_path, is_transform=True)\n",
    "        v_loader = SUNRGBDLoader(data_path, is_transform=True, split='val')\n",
    "\n",
    "    n_classes = t_loader.n_classes\n",
    "    trainloader = data.DataLoader(t_loader, batch_size=args.batch_size, num_workers=16, shuffle=True)\n",
    "    valloader = data.DataLoader(v_loader, batch_size=args.batch_size, num_workers=16)\n",
    "\n",
    "    # Setup Metrics\n",
    "    running_metrics = runningScore(n_classes)\n",
    "\n",
    "    # Setup Model\n",
    "    print(model_name)\n",
    "    model = get_model(model_name, n_classes)\n",
    "    state = convert_state_dict(torch.load(args.model_path)['model_state'])\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    for i, (images, depths, labels) in enumerate(valloader):\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        images = Variable(images.cuda(), volatile=True)\n",
    "        depths = Variable(depths.cuda(), volatile=True)\n",
    "        #labels = Variable(labels.cuda(), volatile=True)\n",
    "\n",
    "        if (model_name == 'fcn8s'):\n",
    "            outputs = model(images)\n",
    "        else:\n",
    "            outputs = model(images, depths)\n",
    "\n",
    "        pred = outputs.data.max(1)[1].cpu().numpy()\n",
    "\n",
    "        #gt = labels.data.cpu().numpy()\n",
    "        gt = labels.numpy()\n",
    "\n",
    "        if args.measure_time:\n",
    "            elapsed_time = timeit.default_timer() - start_time\n",
    "            # print('Inference time (iter {0:5d}): {1:3.5f} fps'.format(i+1, pred.shape[0]/elapsed_time))\n",
    "            sys.stdout.write('.')\n",
    "        running_metrics.update(gt, pred)\n",
    "\n",
    "    score, class_iou = running_metrics.get_scores()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        print(k, v)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        print(i, class_iou[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn8s_rgbd_renet\n"
     ]
    }
   ],
   "source": [
    "validate(parser.parse_args('--model_path fcn8s_rgbd_renet_SUNRGBD_best_model.pkl --model_name fcn8s_rgbd_renet --dataset SUNRGBD --batch_size 3'.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(parser.parse_args('--model_path fcn8s_SUNRGBD_best_model.pkl --model_name fcn8s --dataset SUNRGBD --batch_size 3'.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
