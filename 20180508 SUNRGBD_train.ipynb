{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import collections\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy.misc as m\n",
    "import scipy.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from SUNRGBDLoader import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "data_path = '/home/dongwonshin/Desktop/Datasets/SUNRGBD/SUNRGBD(light)/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import visdom\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ptsemseg.models import get_model\n",
    "from ptsemseg.loader import get_loader, get_data_path\n",
    "from ptsemseg.metrics import runningScore\n",
    "from ptsemseg.loss import *\n",
    "from ptsemseg.augmentations import *\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Hyperparams')\n",
    "parser.add_argument('--arch', nargs='?', type=str, default='fcn8s', \n",
    "                    help='Architecture to use [\\'fcn8s, unet, segnet etc\\']')\n",
    "parser.add_argument('--img_rows', nargs='?', type=int, default=256, \n",
    "                    help='Height of the input image')\n",
    "parser.add_argument('--img_cols', nargs='?', type=int, default=256, \n",
    "                    help='Width of the input image')\n",
    "\n",
    "parser.add_argument('--img_norm', dest='img_norm', action='store_true', \n",
    "                    help='Enable input image scales normalization [0, 1] | True by default')\n",
    "parser.add_argument('--no-img_norm', dest='img_norm', action='store_false', \n",
    "                    help='Disable input image scales normalization [0, 1] | True by default')\n",
    "parser.set_defaults(img_norm=True)\n",
    "\n",
    "parser.add_argument('--n_epoch', nargs='?', type=int, default=100, \n",
    "                    help='# of the epochs')\n",
    "parser.add_argument('--batch_size', nargs='?', type=int, default=1, \n",
    "                    help='Batch Size')\n",
    "parser.add_argument('--l_rate', nargs='?', type=float, default=1e-5, \n",
    "                    help='Learning Rate')\n",
    "parser.add_argument('--feature_scale', nargs='?', type=int, default=1, \n",
    "                    help='Divider for # of features to use')\n",
    "parser.add_argument('--resume', nargs='?', type=str, default=None,    \n",
    "                    help='Path to previous saved model to restart from')\n",
    "\n",
    "parser.add_argument('--visdom', dest='visdom', action='store_true', \n",
    "                    help='Enable visualization(s) on visdom | False by default')\n",
    "parser.add_argument('--no-visdom', dest='visdom', action='store_false', \n",
    "                    help='Disable visualization(s) on visdom | False by default')\n",
    "parser.set_defaults(visdom=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args('--arch fcn8s --batch_size 3'.split(' '))\n",
    "\n",
    "# Setup Augmentations\n",
    "data_aug= Compose([RandomRotate(10),                                        \n",
    "                   RandomHorizontallyFlip()])\n",
    "\n",
    "# Setup Dataloader\n",
    "t_loader = SUNRGBDLoader(data_path, is_transform=True)\n",
    "v_loader = SUNRGBDLoader(data_path, is_transform=True, split='val')\n",
    "\n",
    "n_classes = t_loader.n_classes\n",
    "trainloader = data.DataLoader(t_loader, batch_size=args.batch_size, num_workers=16, shuffle=True)\n",
    "valloader = data.DataLoader(v_loader, batch_size=args.batch_size, num_workers=16)\n",
    "\n",
    "# Setup Metrics\n",
    "running_metrics = runningScore(n_classes)\n",
    "\n",
    "# Setup visdom for visualization\n",
    "if args.visdom:\n",
    "    vis = visdom.Visdom()\n",
    "\n",
    "    loss_window = vis.line(X=torch.zeros((1,)).cpu(),\n",
    "                       Y=torch.zeros((1)).cpu(),\n",
    "                       opts=dict(xlabel='minibatches',\n",
    "                                 ylabel='Loss',\n",
    "                                 title='Training Loss',\n",
    "                                 legend=['Loss']))\n",
    "\n",
    "# Setup Model\n",
    "model = get_model(args.arch, n_classes)\n",
    "\n",
    "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "model.cuda()\n",
    "\n",
    "# Check if model has custom optimizer / loss\n",
    "if hasattr(model.module, 'optimizer'):\n",
    "    optimizer = model.module.optimizer\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.l_rate, momentum=0.99, weight_decay=5e-4)\n",
    "\n",
    "if hasattr(model.module, 'loss'):\n",
    "    print('Using custom loss')\n",
    "    loss_fn = model.module.loss\n",
    "else:\n",
    "    loss_fn = cross_entropy2d\n",
    "\n",
    "if args.resume is not None:                                         \n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"Loading model and optimizer from checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        print(\"Loaded checkpoint '{}' (epoch {})\"                    \n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"No checkpoint found at '{}'\".format(args.resume)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongwonshin/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1462: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n",
      "34it [00:05,  6.53it/s]\n",
      "/home/dongwonshin/Desktop/pytorch_dataloader/ptsemseg/metrics.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: \t 0.0803662760417\n",
      "Mean Acc : \t 0.0305001995634\n",
      "FreqW Acc : \t 0.045001084247\n",
      "Mean IoU : \t 0.00904644702284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: \t 0.250760709635\n",
      "Mean Acc : \t 0.031542331407\n",
      "FreqW Acc : \t 0.0901940687861\n",
      "Mean IoU : \t 0.0113596419677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: \t 0.283253515625\n",
      "Mean Acc : \t 0.034946218269\n",
      "FreqW Acc : \t 0.118222232513\n",
      "Mean IoU : \t 0.0142712547629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: \t 0.290424186198\n",
      "Mean Acc : \t 0.0467739491853\n",
      "FreqW Acc : \t 0.141056101205\n",
      "Mean IoU : \t 0.0197791270722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: \t 0.306995898438\n",
      "Mean Acc : \t 0.0479300288719\n",
      "FreqW Acc : \t 0.151200128425\n",
      "Mean IoU : \t 0.0208737220051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: \t 0.334046354167\n",
      "Mean Acc : \t 0.0461630336062\n",
      "FreqW Acc : \t 0.171481237848\n",
      "Mean IoU : \t 0.022972971074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: \t 0.357367578125\n",
      "Mean Acc : \t 0.0516113899178\n",
      "FreqW Acc : \t 0.195391262636\n",
      "Mean IoU : \t 0.0267318031892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  4.84it/s]"
     ]
    }
   ],
   "source": [
    "best_iou = -100.0 \n",
    "for epoch in range(args.n_epoch):\n",
    "    model.train()\n",
    "    for i, (color_imgs, depth_imgs, label_imgs) in enumerate(trainloader):\n",
    "        images = Variable(color_imgs.cuda())\n",
    "        labels = Variable(label_imgs.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = loss_fn(input=outputs, target=labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if args.visdom:\n",
    "            vis.line(\n",
    "                X=torch.ones((1, 1)).cpu() * i,\n",
    "                Y=torch.Tensor([loss.data[0]]).unsqueeze(0).cpu(),\n",
    "                win=loss_window,\n",
    "                update='append')\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"Epoch [%d/%d] Loss: %.4f\" % (epoch+1, args.n_epoch, loss.data[0]))\n",
    "\n",
    "    model.eval()\n",
    "    for i_val, (color_images_val, depth_images_val, label_images_val) in tqdm(enumerate(valloader)):\n",
    "        images_val = Variable(color_images_val.cuda(), volatile=True)\n",
    "        labels_val = Variable(label_images_val.cuda(), volatile=True)\n",
    "\n",
    "        outputs = model(images_val)\n",
    "        pred = outputs.data.max(1)[1].cpu().numpy()\n",
    "        gt = labels_val.data.cpu().numpy()\n",
    "        running_metrics.update(gt, pred)\n",
    "\n",
    "    score, class_iou = running_metrics.get_scores()\n",
    "    for k, v in score.items():\n",
    "        print(k, v)\n",
    "    running_metrics.reset()\n",
    "\n",
    "    if score['Mean IoU : \\t'] >= best_iou:\n",
    "        best_iou = score['Mean IoU : \\t']\n",
    "        state = {'epoch': epoch+1,\n",
    "                 'model_state': model.state_dict(),\n",
    "                 'optimizer_state' : optimizer.state_dict(),}\n",
    "        torch.save(state, \"{}_{}_best_model.pkl\".format(args.arch, 'SUNRGBD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
